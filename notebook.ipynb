{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "tar_file = r'D:\\PyCharmMiscProject\\slo.zip'\n",
    "\n",
    "extract_dir = 'working'\n",
    "\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(tar_file, 'r') as tar:\n",
    "    tar.extractall(path=extract_dir)\n",
    "\n",
    "print(\"Extraction completed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:18:51.919922Z",
     "start_time": "2025-07-28T18:18:26.341989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install datasets\n",
    "!pip install soundfile\n",
    "!pip install hf_xet"
   ],
   "id": "df1c6ebc17789a05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in d:\\pythonproject\\.venv\\lib\\site-packages (4.53.3)\n",
      "Requirement already satisfied: filelock in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (2.7.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from transformers[torch]) (1.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\pythonproject\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.14.1)\n",
      "Requirement already satisfied: psutil in d:\\pythonproject\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\pythonproject\\.venv\\lib\\site-packages (from torch>=2.1->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\pythonproject\\.venv\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\pythonproject\\.venv\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\pythonproject\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from jinja2->torch>=2.1->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2025.7.14)\n",
      "Requirement already satisfied: datasets in d:\\pythonproject\\.venv\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: packaging in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\pythonproject\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in d:\\pythonproject\\.venv\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
      "Requirement already satisfied: colorama in d:\\pythonproject\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pythonproject\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pythonproject\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\pythonproject\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pythonproject\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: soundfile in d:\\pythonproject\\.venv\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\pythonproject\\.venv\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in d:\\pythonproject\\.venv\\lib\\site-packages (from soundfile) (2.3.1)\n",
      "Requirement already satisfied: pycparser in d:\\pythonproject\\.venv\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: hf_xet in d:\\pythonproject\\.venv\\lib\\site-packages (1.1.5)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:18:59.940525Z",
     "start_time": "2025-07-28T18:18:53.463912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base_path = Path(\"working\")\n",
    "metadata_files = list(base_path.rglob(\"*.tsv\"))\n",
    "\n",
    "train_path = next(p for p in metadata_files if \"train\" in p.name)\n",
    "validated_path = next(p for p in metadata_files if \"validated\" in p.name)\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\")\n",
    "validated_df = pd.read_csv(validated_path, sep=\"\\t\")\n",
    "\n",
    "main_df = pd.concat([train_df, validated_df], ignore_index=True)\n",
    "\n",
    "def ensure_mp3_extension(p):\n",
    "    return p if p.endswith(\".mp3\") else p + \".mp3\"\n",
    "\n",
    "main_df[\"path\"] = main_df[\"path\"].apply(ensure_mp3_extension)\n",
    "\n",
    "clips_dir = base_path / \"clips\"\n",
    "main_df[\"audio_path\"] = main_df[\"path\"].apply(lambda p: (clips_dir / p).as_posix())\n",
    "\n",
    "main_df[\"exists\"] = main_df[\"audio_path\"].apply(lambda p: Path(p).exists())\n",
    "\n",
    "valid_df = main_df[main_df[\"exists\"]].reset_index(drop=True)\n",
    "\n",
    "print(f\"Valid audio samples: {len(valid_df)}\")"
   ],
   "id": "1fa438bed83b9215",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid audio samples: 1307\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    " Wav2Vec2ForCTC,TrainingArguments, Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "from jiwer import wer, cer\n",
    "\n",
    "\n",
    "def prepare_dataset(df, sampling_rate=16000):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input DataFrame is empty.\")\n",
    "    df = df.rename(columns={'audio_path': 'audio', 'sentence': 'text'})\n",
    "    ds = Dataset.from_pandas(df[[\"audio\", \"text\"]])\n",
    "    return ds"
   ],
   "id": "5152095a11e16095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "def load_audio_pydub(path, target_sampling_rate=16000):\n",
    "    audio = AudioSegment.from_file(path)\n",
    "    if audio.frame_rate != target_sampling_rate:\n",
    "        audio = audio.set_frame_rate(target_sampling_rate)\n",
    "    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / (2**15)\n",
    "    if audio.channels > 1:\n",
    "        samples = samples.reshape((-1, audio.channels)).mean(axis=1)\n",
    "    return samples, target_sampling_rate"
   ],
   "id": "3dd2dc8069360463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:19:59.019184Z",
     "start_time": "2025-07-28T18:19:00.015705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"mrshu/wav2vec2-large-xlsr-slovene\")\n",
    "\n",
    "def preprocess_single_example(example, processor, sampling_rate=16000):\n",
    "        from pydub import AudioSegment\n",
    "        import numpy as np\n",
    "\n",
    "        path = example[\"audio\"]\n",
    "        text = example[\"text\"]\n",
    "\n",
    "        audio = AudioSegment.from_file(path)\n",
    "        if audio.frame_rate != sampling_rate:\n",
    "            audio = audio.set_frame_rate(sampling_rate)\n",
    "        samples = np.array(audio.get_array_of_samples()).astype(np.float32) / (2**15)\n",
    "        if audio.channels > 1:\n",
    "            samples = samples.reshape((-1, audio.channels)).mean(axis=1)\n",
    "\n",
    "        inputs = processor(samples, sampling_rate=sampling_rate, padding=True, return_attention_mask=False)\n",
    "\n",
    "        with processor.as_target_processor():\n",
    "            labels = processor(text).input_ids\n",
    "\n",
    "        return {\n",
    "            \"input_values\": inputs.input_values[0],\n",
    "            \"attention_mask\": inputs.attention_mask[0],\n",
    "            \"labels\": labels\n",
    "        }"
   ],
   "id": "d569a00d1a7acf94",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:309: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "        processor: Wav2Vec2Processor\n",
    "        padding: Union[bool, str] = True\n",
    "\n",
    "        def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "            input_features = [{\"input_values\":f[\"input_values\"]} for f in features]\n",
    "            label_features = [{\"input_ids\":f[\"labels\"]} for f in features]\n",
    "\n",
    "            batch = self.processor.pad(\n",
    "                input_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            with self.processor.as_target_processor():\n",
    "                labels_batch = self.processor.pad(\n",
    "                    label_features,\n",
    "                    padding=self.padding,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "            labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "            batch[\"labels\"] = labels\n",
    "\n",
    "            return batch"
   ],
   "id": "ec834c775e79f2df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def quick_test_training(dataset, max_samples=100):\n",
    "    print(f\"Running quick test with {max_samples} samples...\")\n",
    "\n",
    "    from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        MODEL_NAME = \"mrshu/wav2vec2-large-xlsr-slovene\"\n",
    "        SAMPLING_RATE = 16000\n",
    "        NUM_EPOCHS = 2\n",
    "        BATCH_SIZE = 4\n",
    "        OUTPUT_DIR = \"./wav2vec2-test\"\n",
    "\n",
    "    small_dataset = dataset.select(range(min(max_samples, len(dataset))))\n",
    "\n",
    "    processor = Wav2Vec2Processor.from_pretrained(Config.MODEL_NAME)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\n",
    "        Config.MODEL_NAME,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        vocab_size=len(processor.tokenizer)\n",
    "    )\n",
    "\n",
    "    model.freeze_feature_encoder()\n",
    "\n",
    "    print(\"Processing dataset...\")\n",
    "    processed_dataset = small_dataset.map(\n",
    "        lambda x: preprocess_single_example(x, processor),\n",
    "        remove_columns=small_dataset.column_names,\n",
    "        desc=\"Processing audio files\"\n",
    "    ).filter(lambda x: x is not None)\n",
    "\n",
    "    print(f\"Processed {len(processed_dataset)} examples\")\n",
    "\n",
    "    split = processed_dataset.train_test_split(test_size=0.1)\n",
    "    train_dataset = split[\"train\"]\n",
    "    eval_dataset = split[\"test\"]\n",
    "\n",
    "    data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=Config.OUTPUT_DIR,\n",
    "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
    "        eval_strategy=\"steps\",\n",
    "        logging_dir=f\"{Config.OUTPUT_DIR}/logs\",\n",
    "        logging_strategy=\"steps\",\n",
    "        num_train_epochs=Config.NUM_EPOCHS,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        logging_steps=5,\n",
    "        save_total_limit=2,\n",
    "        fp16=True,\n",
    "        report_to=[],\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_drop_last=False,\n",
    "        group_by_length=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=processor.feature_extractor,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    return trainer, processor"
   ],
   "id": "22ab80cf6717f2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"mrshu/wav2vec2-large-xlsr-slovene\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_NAME, vocab_size=len(processor.tokenizer), ignore_mismatched_sizes=True)\n",
    "model.freeze_feature_encoder()"
   ],
   "id": "26d80235de8b4928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = prepare_dataset(valid_df)\n",
    "ds = dataset.map(lambda x: preprocess_single_example(x, processor), remove_columns=dataset.column_names)"
   ],
   "id": "de558bfc2d5d119a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "split_ds = ds.train_test_split(test_size=0.1)\n",
    "train_ds = split_ds[\"train\"]\n",
    "eval_ds = split_ds[\"test\"]"
   ],
   "id": "7bbe0fb54aa7b9b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-slovene\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    fp16=True,\n",
    "    learning_rate=3e-4,\n",
    "    save_total_limit=2,\n",
    "    group_by_length=True,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],\n",
    "    logging_dir=\"./logs\"\n",
    ")"
   ],
   "id": "7c8c6e0bd7791e3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer(label_str, pred_str),\n",
    "        \"cer\": cer(label_str, pred_str)\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor)\n"
   ],
   "id": "28b9591834b86437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "396f25c197721735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"./wav2vec2-slovene\")\n",
    "processor.save_pretrained(\"./wav2vec2-slovene\")"
   ],
   "id": "d7ed141b1ff39c9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ],
   "id": "8a0cccd3ba67c5fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "86b1f9d6ad147c01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:20:01.640932Z",
     "start_time": "2025-07-28T18:19:59.059601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Union\n",
    "from pydub import AudioSegment\n",
    "from jiwer import wer\n"
   ],
   "id": "9fc1a50b5ef3f9db",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:20:08.506169Z",
     "start_time": "2025-07-28T18:20:01.672951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"mrshu/wav2vec2-large-xlsr-slovene\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.freeze_feature_encoder()"
   ],
   "id": "991caae48f1e6dd9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:309: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at mrshu/wav2vec2-large-xlsr-slovene and are newly initialized because the shapes did not match:\n",
      "- lm_head.weight: found shape torch.Size([31, 1024]) in the checkpoint and torch.Size([33, 1024]) in the model instantiated\n",
      "- lm_head.bias: found shape torch.Size([31]) in the checkpoint and torch.Size([33]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:20:08.558925Z",
     "start_time": "2025-07-28T18:20:08.551285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_audio(path):\n",
    "    audio = AudioSegment.from_file(path).set_frame_rate(16000)\n",
    "    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / (2**15)\n",
    "    print(\"Sample length:\", len(samples))\n",
    "    if audio.channels > 1:\n",
    "        samples = samples.reshape((-1, audio.channels)).mean(axis=1)\n",
    "    return samples"
   ],
   "id": "54efaca3f0e9933c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:20:08.616541Z",
     "start_time": "2025-07-28T18:20:08.605896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(batch):\n",
    "    audio_inputs = [load_audio(p) for p in batch[\"audio_path\"]]\n",
    "\n",
    "    inputs = processor.feature_extractor(\n",
    "        audio_inputs,\n",
    "        sampling_rate=16000,\n",
    "        return_attention_mask=True,\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    with processor.as_target_processor():\n",
    "        label_batch = processor.tokenizer(\n",
    "            batch[\"sentence\"],\n",
    "            padding=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "\n",
    "    labels = label_batch[\"input_ids\"]\n",
    "    print(\"Decoded label:\", processor.tokenizer.batch_decode(labels, skip_special_tokens=True)[0])\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n"
   ],
   "id": "10d8ed7cb56b0ec2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:52:36.414817Z",
     "start_time": "2025-07-28T18:43:54.855895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = Dataset.from_pandas(valid_df[[\"audio_path\", \"sentence\"]])\n",
    "ds = ds.map(preprocess, batched=True, remove_columns=ds.column_names)\n",
    "\n",
    "split = ds.train_test_split(test_size=0.1)\n",
    "train_ds, eval_ds = split[\"train\"], split[\"test\"]"
   ],
   "id": "cad3b6173227198f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1307 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample length: 54528\n",
      "Sample length: 46464\n",
      "Sample length: 51456\n",
      "Sample length: 66048\n",
      "Sample length: 60288\n",
      "Sample length: 47232\n",
      "Sample length: 64512\n",
      "Sample length: 60672\n",
      "Sample length: 59136\n",
      "Sample length: 72192\n",
      "Sample length: 40320\n",
      "Sample length: 31872\n",
      "Sample length: 45312\n",
      "Sample length: 45312\n",
      "Sample length: 70272\n",
      "Sample length: 68352\n",
      "Sample length: 92160\n",
      "Sample length: 58368\n",
      "Sample length: 96768\n",
      "Sample length: 53760\n",
      "Sample length: 53760\n",
      "Sample length: 75264\n",
      "Sample length: 45312\n",
      "Sample length: 67200\n",
      "Sample length: 98304\n",
      "Sample length: 40320\n",
      "Sample length: 86400\n",
      "Sample length: 46080\n",
      "Sample length: 39168\n",
      "Sample length: 36480\n",
      "Sample length: 63744\n",
      "Sample length: 49536\n",
      "Sample length: 67584\n",
      "Sample length: 26880\n",
      "Sample length: 56832\n",
      "Sample length: 65280\n",
      "Sample length: 50688\n",
      "Sample length: 46848\n",
      "Sample length: 69504\n",
      "Sample length: 43776\n",
      "Sample length: 31872\n",
      "Sample length: 53760\n",
      "Sample length: 61440\n",
      "Sample length: 40704\n",
      "Sample length: 53760\n",
      "Sample length: 43776\n",
      "Sample length: 44160\n",
      "Sample length: 41472\n",
      "Sample length: 39552\n",
      "Sample length: 31488\n",
      "Sample length: 72576\n",
      "Sample length: 56448\n",
      "Sample length: 80256\n",
      "Sample length: 32256\n",
      "Sample length: 42624\n",
      "Sample length: 27648\n",
      "Sample length: 59520\n",
      "Sample length: 79104\n",
      "Sample length: 56448\n",
      "Sample length: 55296\n",
      "Sample length: 45696\n",
      "Sample length: 38784\n",
      "Sample length: 41088\n",
      "Sample length: 54144\n",
      "Sample length: 48768\n",
      "Sample length: 61056\n",
      "Sample length: 45696\n",
      "Sample length: 54528\n",
      "Sample length: 56832\n",
      "Sample length: 60672\n",
      "Sample length: 37248\n",
      "Sample length: 45696\n",
      "Sample length: 89856\n",
      "Sample length: 38400\n",
      "Sample length: 51456\n",
      "Sample length: 65280\n",
      "Sample length: 47232\n",
      "Sample length: 78720\n",
      "Sample length: 54528\n",
      "Sample length: 42240\n",
      "Sample length: 89856\n",
      "Sample length: 61056\n",
      "Sample length: 43392\n",
      "Sample length: 58368\n",
      "Sample length: 59520\n",
      "Sample length: 48000\n",
      "Sample length: 54144\n",
      "Sample length: 26112\n",
      "Sample length: 38784\n",
      "Sample length: 33408\n",
      "Sample length: 56064\n",
      "Sample length: 49920\n",
      "Sample length: 35712\n",
      "Sample length: 50688\n",
      "Sample length: 57984\n",
      "Sample length: 44928\n",
      "Sample length: 37248\n",
      "Sample length: 51456\n",
      "Sample length: 38784\n",
      "Sample length: 63360\n",
      "Sample length: 58752\n",
      "Sample length: 61056\n",
      "Sample length: 38016\n",
      "Sample length: 64512\n",
      "Sample length: 42624\n",
      "Sample length: 33408\n",
      "Sample length: 80640\n",
      "Sample length: 26112\n",
      "Sample length: 74496\n",
      "Sample length: 89856\n",
      "Sample length: 47232\n",
      "Sample length: 52224\n",
      "Sample length: 36480\n",
      "Sample length: 57216\n",
      "Sample length: 47232\n",
      "Sample length: 67968\n",
      "Sample length: 46080\n",
      "Sample length: 51456\n",
      "Sample length: 55680\n",
      "Sample length: 49152\n",
      "Sample length: 31104\n",
      "Sample length: 56832\n",
      "Sample length: 39552\n",
      "Sample length: 55296\n",
      "Sample length: 33792\n",
      "Sample length: 53376\n",
      "Sample length: 63744\n",
      "Sample length: 57984\n",
      "Sample length: 97920\n",
      "Sample length: 56064\n",
      "Sample length: 78336\n",
      "Sample length: 66432\n",
      "Sample length: 34176\n",
      "Sample length: 84096\n",
      "Sample length: 81792\n",
      "Sample length: 89472\n",
      "Sample length: 84480\n",
      "Sample length: 52992\n",
      "Sample length: 71808\n",
      "Sample length: 38400\n",
      "Sample length: 44544\n",
      "Sample length: 63360\n",
      "Sample length: 66432\n",
      "Sample length: 29184\n",
      "Sample length: 32256\n",
      "Sample length: 65664\n",
      "Sample length: 84096\n",
      "Sample length: 59904\n",
      "Sample length: 53760\n",
      "Sample length: 62592\n",
      "Sample length: 59904\n",
      "Sample length: 78336\n",
      "Sample length: 56832\n",
      "Sample length: 49920\n",
      "Sample length: 66816\n",
      "Sample length: 48384\n",
      "Sample length: 62208\n",
      "Sample length: 61440\n",
      "Sample length: 84096\n",
      "Sample length: 40320\n",
      "Sample length: 58368\n",
      "Sample length: 35328\n",
      "Sample length: 55296\n",
      "Sample length: 79488\n",
      "Sample length: 50688\n",
      "Sample length: 65664\n",
      "Sample length: 80640\n",
      "Sample length: 29568\n",
      "Sample length: 29568\n",
      "Sample length: 66048\n",
      "Sample length: 56832\n",
      "Sample length: 88320\n",
      "Sample length: 26880\n",
      "Sample length: 49920\n",
      "Sample length: 56064\n",
      "Sample length: 51072\n",
      "Sample length: 42240\n",
      "Sample length: 97920\n",
      "Sample length: 45312\n",
      "Sample length: 58752\n",
      "Sample length: 59904\n",
      "Sample length: 56064\n",
      "Sample length: 44160\n",
      "Sample length: 80640\n",
      "Sample length: 30720\n",
      "Sample length: 59904\n",
      "Sample length: 46848\n",
      "Sample length: 52992\n",
      "Sample length: 52992\n",
      "Sample length: 31872\n",
      "Sample length: 59904\n",
      "Sample length: 76416\n",
      "Sample length: 31104\n",
      "Sample length: 26880\n",
      "Sample length: 57216\n",
      "Sample length: 54912\n",
      "Sample length: 71808\n",
      "Sample length: 77184\n",
      "Sample length: 49920\n",
      "Sample length: 42624\n",
      "Sample length: 67584\n",
      "Sample length: 60288\n",
      "Sample length: 55680\n",
      "Sample length: 40704\n",
      "Sample length: 48000\n",
      "Sample length: 34176\n",
      "Sample length: 52992\n",
      "Sample length: 52224\n",
      "Sample length: 62592\n",
      "Sample length: 55680\n",
      "Sample length: 57600\n",
      "Sample length: 80256\n",
      "Sample length: 56448\n",
      "Sample length: 29952\n",
      "Sample length: 31872\n",
      "Sample length: 32640\n",
      "Sample length: 54144\n",
      "Sample length: 56064\n",
      "Sample length: 83712\n",
      "Sample length: 72192\n",
      "Sample length: 32256\n",
      "Sample length: 62592\n",
      "Sample length: 67200\n",
      "Sample length: 29952\n",
      "Sample length: 45312\n",
      "Sample length: 68352\n",
      "Sample length: 84480\n",
      "Sample length: 47232\n",
      "Sample length: 63744\n",
      "Sample length: 50304\n",
      "Sample length: 75264\n",
      "Sample length: 51072\n",
      "Sample length: 83712\n",
      "Sample length: 55680\n",
      "Sample length: 54528\n",
      "Sample length: 34560\n",
      "Sample length: 59136\n",
      "Sample length: 32640\n",
      "Sample length: 33408\n",
      "Sample length: 50688\n",
      "Sample length: 53376\n",
      "Sample length: 59136\n",
      "Sample length: 44160\n",
      "Sample length: 70272\n",
      "Sample length: 72576\n",
      "Sample length: 66432\n",
      "Sample length: 55680\n",
      "Sample length: 48000\n",
      "Sample length: 55296\n",
      "Sample length: 47616\n",
      "Sample length: 36480\n",
      "Sample length: 58368\n",
      "Sample length: 42624\n",
      "Sample length: 38400\n",
      "Sample length: 56064\n",
      "Sample length: 56832\n",
      "Sample length: 50688\n",
      "Sample length: 74880\n",
      "Sample length: 74880\n",
      "Sample length: 53760\n",
      "Sample length: 26880\n",
      "Sample length: 51072\n",
      "Sample length: 76032\n",
      "Sample length: 71040\n",
      "Sample length: 51456\n",
      "Sample length: 77184\n",
      "Sample length: 44928\n",
      "Sample length: 89088\n",
      "Sample length: 40704\n",
      "Sample length: 66432\n",
      "Sample length: 46848\n",
      "Sample length: 33408\n",
      "Sample length: 77952\n",
      "Sample length: 57216\n",
      "Sample length: 91776\n",
      "Sample length: 78720\n",
      "Sample length: 110976\n",
      "Sample length: 57216\n",
      "Sample length: 67584\n",
      "Sample length: 43008\n",
      "Sample length: 71424\n",
      "Sample length: 65280\n",
      "Sample length: 85248\n",
      "Sample length: 98688\n",
      "Sample length: 49920\n",
      "Sample length: 50688\n",
      "Sample length: 39168\n",
      "Sample length: 58752\n",
      "Sample length: 62592\n",
      "Sample length: 49536\n",
      "Sample length: 89856\n",
      "Sample length: 60672\n",
      "Sample length: 41472\n",
      "Sample length: 58368\n",
      "Sample length: 55680\n",
      "Sample length: 74112\n",
      "Sample length: 76416\n",
      "Sample length: 66816\n",
      "Sample length: 70656\n",
      "Sample length: 68736\n",
      "Sample length: 62592\n",
      "Sample length: 66432\n",
      "Sample length: 38784\n",
      "Sample length: 111744\n",
      "Sample length: 71040\n",
      "Sample length: 44160\n",
      "Sample length: 85248\n",
      "Sample length: 66432\n",
      "Sample length: 63744\n",
      "Sample length: 79872\n",
      "Sample length: 62976\n",
      "Sample length: 49920\n",
      "Sample length: 66816\n",
      "Sample length: 46848\n",
      "Sample length: 97920\n",
      "Sample length: 44544\n",
      "Sample length: 40704\n",
      "Sample length: 46848\n",
      "Sample length: 65280\n",
      "Sample length: 67968\n",
      "Sample length: 63360\n",
      "Sample length: 43392\n",
      "Sample length: 54144\n",
      "Sample length: 82560\n",
      "Sample length: 40320\n",
      "Sample length: 66048\n",
      "Sample length: 86400\n",
      "Sample length: 37248\n",
      "Sample length: 44544\n",
      "Sample length: 63744\n",
      "Sample length: 48384\n",
      "Sample length: 102144\n",
      "Sample length: 38400\n",
      "Sample length: 32640\n",
      "Sample length: 32640\n",
      "Sample length: 78336\n",
      "Sample length: 49536\n",
      "Sample length: 71424\n",
      "Sample length: 76032\n",
      "Sample length: 47616\n",
      "Sample length: 42240\n",
      "Sample length: 72576\n",
      "Sample length: 49536\n",
      "Sample length: 44928\n",
      "Sample length: 67200\n",
      "Sample length: 59136\n",
      "Sample length: 83712\n",
      "Sample length: 92544\n",
      "Sample length: 75648\n",
      "Sample length: 38784\n",
      "Sample length: 49152\n",
      "Sample length: 107520\n",
      "Sample length: 64896\n",
      "Sample length: 55680\n",
      "Sample length: 39936\n",
      "Sample length: 54144\n",
      "Sample length: 97920\n",
      "Sample length: 62208\n",
      "Sample length: 90624\n",
      "Sample length: 61824\n",
      "Sample length: 34560\n",
      "Sample length: 32640\n",
      "Sample length: 65664\n",
      "Sample length: 65280\n",
      "Sample length: 69504\n",
      "Sample length: 38784\n",
      "Sample length: 54528\n",
      "Sample length: 45312\n",
      "Sample length: 62208\n",
      "Sample length: 49536\n",
      "Sample length: 76032\n",
      "Sample length: 57600\n",
      "Sample length: 75648\n",
      "Sample length: 49920\n",
      "Sample length: 57984\n",
      "Sample length: 38016\n",
      "Sample length: 63360\n",
      "Sample length: 69120\n",
      "Sample length: 64128\n",
      "Sample length: 42240\n",
      "Sample length: 51840\n",
      "Sample length: 63744\n",
      "Sample length: 47232\n",
      "Sample length: 48384\n",
      "Sample length: 72192\n",
      "Sample length: 54144\n",
      "Sample length: 49536\n",
      "Sample length: 59904\n",
      "Sample length: 67200\n",
      "Sample length: 51840\n",
      "Sample length: 65280\n",
      "Sample length: 43008\n",
      "Sample length: 64512\n",
      "Sample length: 71424\n",
      "Sample length: 37248\n",
      "Sample length: 53760\n",
      "Sample length: 68736\n",
      "Sample length: 41856\n",
      "Sample length: 50688\n",
      "Sample length: 40320\n",
      "Sample length: 59136\n",
      "Sample length: 32640\n",
      "Sample length: 33792\n",
      "Sample length: 35712\n",
      "Sample length: 72576\n",
      "Sample length: 49920\n",
      "Sample length: 74880\n",
      "Sample length: 46848\n",
      "Sample length: 37632\n",
      "Sample length: 83328\n",
      "Sample length: 89472\n",
      "Sample length: 54912\n",
      "Sample length: 56448\n",
      "Sample length: 94080\n",
      "Sample length: 50304\n",
      "Sample length: 84864\n",
      "Sample length: 86016\n",
      "Sample length: 45696\n",
      "Sample length: 49536\n",
      "Sample length: 90240\n",
      "Sample length: 45696\n",
      "Sample length: 36480\n",
      "Sample length: 37632\n",
      "Sample length: 34560\n",
      "Sample length: 78336\n",
      "Sample length: 46848\n",
      "Sample length: 39936\n",
      "Sample length: 50688\n",
      "Sample length: 57600\n",
      "Sample length: 52608\n",
      "Sample length: 27264\n",
      "Sample length: 54144\n",
      "Sample length: 59904\n",
      "Sample length: 55680\n",
      "Sample length: 59136\n",
      "Sample length: 64128\n",
      "Sample length: 57600\n",
      "Sample length: 78720\n",
      "Sample length: 33792\n",
      "Sample length: 46464\n",
      "Sample length: 66816\n",
      "Sample length: 63744\n",
      "Sample length: 72192\n",
      "Sample length: 75264\n",
      "Sample length: 96768\n",
      "Sample length: 68352\n",
      "Sample length: 104448\n",
      "Sample length: 37248\n",
      "Sample length: 56448\n",
      "Sample length: 75264\n",
      "Sample length: 80640\n",
      "Sample length: 29952\n",
      "Sample length: 48384\n",
      "Sample length: 28416\n",
      "Sample length: 38400\n",
      "Sample length: 93312\n",
      "Sample length: 42624\n",
      "Sample length: 96768\n",
      "Sample length: 67200\n",
      "Sample length: 52608\n",
      "Sample length: 50688\n",
      "Sample length: 67200\n",
      "Sample length: 27264\n",
      "Sample length: 94464\n",
      "Sample length: 62976\n",
      "Sample length: 51456\n",
      "Sample length: 83712\n",
      "Sample length: 82560\n",
      "Sample length: 54144\n",
      "Sample length: 80640\n",
      "Sample length: 87168\n",
      "Sample length: 72576\n",
      "Sample length: 39552\n",
      "Sample length: 53760\n",
      "Sample length: 36480\n",
      "Sample length: 72576\n",
      "Sample length: 87168\n",
      "Sample length: 61056\n",
      "Sample length: 37632\n",
      "Sample length: 36864\n",
      "Sample length: 77184\n",
      "Sample length: 58752\n",
      "Sample length: 71808\n",
      "Sample length: 64512\n",
      "Sample length: 51072\n",
      "Sample length: 62976\n",
      "Sample length: 24960\n",
      "Sample length: 37248\n",
      "Sample length: 24192\n",
      "Sample length: 59520\n",
      "Sample length: 59520\n",
      "Sample length: 34944\n",
      "Sample length: 90624\n",
      "Sample length: 27264\n",
      "Sample length: 97152\n",
      "Sample length: 36480\n",
      "Sample length: 37248\n",
      "Sample length: 31488\n",
      "Sample length: 49920\n",
      "Sample length: 64128\n",
      "Sample length: 76032\n",
      "Sample length: 36864\n",
      "Sample length: 22656\n",
      "Sample length: 26880\n",
      "Sample length: 65664\n",
      "Sample length: 80640\n",
      "Sample length: 89856\n",
      "Sample length: 60672\n",
      "Sample length: 53376\n",
      "Sample length: 29184\n",
      "Sample length: 54912\n",
      "Sample length: 63744\n",
      "Sample length: 43776\n",
      "Sample length: 21504\n",
      "Sample length: 65664\n",
      "Sample length: 56448\n",
      "Sample length: 26880\n",
      "Sample length: 78336\n",
      "Sample length: 62976\n",
      "Sample length: 60672\n",
      "Sample length: 41088\n",
      "Sample length: 68736\n",
      "Sample length: 69504\n",
      "Sample length: 46464\n",
      "Sample length: 46080\n",
      "Sample length: 46848\n",
      "Sample length: 49920\n",
      "Sample length: 72576\n",
      "Sample length: 46464\n",
      "Sample length: 55680\n",
      "Sample length: 67200\n",
      "Sample length: 57984\n",
      "Sample length: 49920\n",
      "Sample length: 61056\n",
      "Sample length: 38400\n",
      "Sample length: 60672\n",
      "Sample length: 35328\n",
      "Sample length: 38016\n",
      "Sample length: 32640\n",
      "Sample length: 82176\n",
      "Sample length: 34560\n",
      "Sample length: 49920\n",
      "Sample length: 53376\n",
      "Sample length: 33792\n",
      "Sample length: 46080\n",
      "Sample length: 43776\n",
      "Sample length: 66048\n",
      "Sample length: 75648\n",
      "Sample length: 61824\n",
      "Sample length: 67584\n",
      "Sample length: 49920\n",
      "Sample length: 51840\n",
      "Sample length: 51840\n",
      "Sample length: 89472\n",
      "Sample length: 58752\n",
      "Sample length: 49920\n",
      "Sample length: 57984\n",
      "Sample length: 64512\n",
      "Sample length: 56832\n",
      "Sample length: 63360\n",
      "Sample length: 71424\n",
      "Sample length: 50688\n",
      "Sample length: 54144\n",
      "Sample length: 70272\n",
      "Sample length: 52992\n",
      "Sample length: 63744\n",
      "Sample length: 72960\n",
      "Sample length: 75264\n",
      "Sample length: 51072\n",
      "Sample length: 46080\n",
      "Sample length: 57600\n",
      "Sample length: 34944\n",
      "Sample length: 19584\n",
      "Sample length: 71808\n",
      "Sample length: 95616\n",
      "Sample length: 45312\n",
      "Sample length: 64896\n",
      "Sample length: 67584\n",
      "Sample length: 52608\n",
      "Sample length: 50688\n",
      "Sample length: 54912\n",
      "Sample length: 38016\n",
      "Sample length: 29184\n",
      "Sample length: 71040\n",
      "Sample length: 51840\n",
      "Sample length: 42240\n",
      "Sample length: 45696\n",
      "Sample length: 37248\n",
      "Sample length: 103680\n",
      "Sample length: 24960\n",
      "Sample length: 97152\n",
      "Sample length: 43392\n",
      "Sample length: 75648\n",
      "Sample length: 69504\n",
      "Sample length: 53760\n",
      "Sample length: 33024\n",
      "Sample length: 35328\n",
      "Sample length: 44160\n",
      "Sample length: 44160\n",
      "Sample length: 68736\n",
      "Sample length: 51840\n",
      "Sample length: 43392\n",
      "Sample length: 49920\n",
      "Sample length: 49152\n",
      "Sample length: 99840\n",
      "Sample length: 42624\n",
      "Sample length: 78336\n",
      "Sample length: 70272\n",
      "Sample length: 48000\n",
      "Sample length: 70656\n",
      "Sample length: 54912\n",
      "Sample length: 67200\n",
      "Sample length: 66816\n",
      "Sample length: 41472\n",
      "Sample length: 46848\n",
      "Sample length: 61824\n",
      "Sample length: 73728\n",
      "Sample length: 49920\n",
      "Sample length: 67584\n",
      "Sample length: 72576\n",
      "Sample length: 92928\n",
      "Sample length: 78336\n",
      "Sample length: 63744\n",
      "Sample length: 46080\n",
      "Sample length: 67968\n",
      "Sample length: 77952\n",
      "Sample length: 44928\n",
      "Sample length: 64128\n",
      "Sample length: 67968\n",
      "Sample length: 33408\n",
      "Sample length: 85248\n",
      "Sample length: 56448\n",
      "Sample length: 88320\n",
      "Sample length: 59520\n",
      "Sample length: 69120\n",
      "Sample length: 70656\n",
      "Sample length: 41088\n",
      "Sample length: 60672\n",
      "Sample length: 64512\n",
      "Sample length: 66048\n",
      "Sample length: 81792\n",
      "Sample length: 64128\n",
      "Sample length: 59520\n",
      "Sample length: 54144\n",
      "Sample length: 60672\n",
      "Sample length: 77952\n",
      "Sample length: 39936\n",
      "Sample length: 66816\n",
      "Sample length: 66432\n",
      "Sample length: 77568\n",
      "Sample length: 44928\n",
      "Sample length: 71808\n",
      "Sample length: 75264\n",
      "Sample length: 72192\n",
      "Sample length: 53376\n",
      "Sample length: 84096\n",
      "Sample length: 55296\n",
      "Sample length: 80640\n",
      "Sample length: 71424\n",
      "Sample length: 69888\n",
      "Sample length: 56448\n",
      "Sample length: 49920\n",
      "Sample length: 38400\n",
      "Sample length: 40704\n",
      "Sample length: 53376\n",
      "Sample length: 74496\n",
      "Sample length: 104064\n",
      "Sample length: 40704\n",
      "Sample length: 64128\n",
      "Sample length: 38016\n",
      "Sample length: 52224\n",
      "Sample length: 75264\n",
      "Sample length: 57600\n",
      "Sample length: 49920\n",
      "Sample length: 66816\n",
      "Sample length: 54144\n",
      "Sample length: 43776\n",
      "Sample length: 61440\n",
      "Sample length: 71424\n",
      "Sample length: 57600\n",
      "Sample length: 72576\n",
      "Sample length: 48768\n",
      "Sample length: 61824\n",
      "Sample length: 63360\n",
      "Sample length: 69120\n",
      "Sample length: 49920\n",
      "Sample length: 57600\n",
      "Sample length: 68352\n",
      "Sample length: 50304\n",
      "Sample length: 49152\n",
      "Sample length: 46848\n",
      "Sample length: 60672\n",
      "Sample length: 59520\n",
      "Sample length: 59520\n",
      "Sample length: 72576\n",
      "Sample length: 40704\n",
      "Sample length: 58368\n",
      "Sample length: 54912\n",
      "Sample length: 66432\n",
      "Sample length: 62208\n",
      "Sample length: 76416\n",
      "Sample length: 67584\n",
      "Sample length: 84480\n",
      "Sample length: 70272\n",
      "Sample length: 72192\n",
      "Sample length: 52608\n",
      "Sample length: 52608\n",
      "Sample length: 75648\n",
      "Sample length: 76032\n",
      "Sample length: 43392\n",
      "Sample length: 61824\n",
      "Sample length: 71808\n",
      "Sample length: 61056\n",
      "Sample length: 61440\n",
      "Sample length: 64512\n",
      "Sample length: 48000\n",
      "Sample length: 67584\n",
      "Sample length: 51072\n",
      "Sample length: 62592\n",
      "Sample length: 79104\n",
      "Sample length: 54528\n",
      "Sample length: 68736\n",
      "Sample length: 45696\n",
      "Sample length: 56448\n",
      "Sample length: 61056\n",
      "Sample length: 60672\n",
      "Sample length: 78336\n",
      "Sample length: 55680\n",
      "Sample length: 43392\n",
      "Sample length: 61440\n",
      "Sample length: 75648\n",
      "Sample length: 53760\n",
      "Sample length: 51840\n",
      "Sample length: 95232\n",
      "Sample length: 31488\n",
      "Sample length: 81024\n",
      "Sample length: 103680\n",
      "Sample length: 67200\n",
      "Sample length: 89088\n",
      "Sample length: 69504\n",
      "Sample length: 67968\n",
      "Sample length: 65664\n",
      "Sample length: 51456\n",
      "Sample length: 82176\n",
      "Sample length: 70272\n",
      "Sample length: 66816\n",
      "Sample length: 98304\n",
      "Sample length: 76416\n",
      "Sample length: 47616\n",
      "Sample length: 46848\n",
      "Sample length: 77568\n",
      "Sample length: 77184\n",
      "Sample length: 73344\n",
      "Sample length: 55296\n",
      "Sample length: 70656\n",
      "Sample length: 46464\n",
      "Sample length: 55680\n",
      "Sample length: 65280\n",
      "Sample length: 71424\n",
      "Sample length: 47616\n",
      "Sample length: 86016\n",
      "Sample length: 57600\n",
      "Sample length: 75648\n",
      "Sample length: 80256\n",
      "Sample length: 104832\n",
      "Sample length: 72960\n",
      "Sample length: 74112\n",
      "Sample length: 60672\n",
      "Sample length: 48000\n",
      "Sample length: 64512\n",
      "Sample length: 62592\n",
      "Sample length: 88320\n",
      "Sample length: 75264\n",
      "Sample length: 42624\n",
      "Sample length: 104064\n",
      "Sample length: 66432\n",
      "Sample length: 52224\n",
      "Sample length: 71424\n",
      "Sample length: 50304\n",
      "Sample length: 82176\n",
      "Sample length: 56448\n",
      "Sample length: 50688\n",
      "Sample length: 73728\n",
      "Sample length: 73344\n",
      "Sample length: 67200\n",
      "Sample length: 83328\n",
      "Sample length: 63360\n",
      "Sample length: 78720\n",
      "Sample length: 57600\n",
      "Sample length: 96384\n",
      "Sample length: 86016\n",
      "Sample length: 59520\n",
      "Sample length: 45696\n",
      "Sample length: 54144\n",
      "Sample length: 55680\n",
      "Sample length: 76416\n",
      "Sample length: 87168\n",
      "Sample length: 52224\n",
      "Sample length: 75648\n",
      "Sample length: 68736\n",
      "Sample length: 43008\n",
      "Sample length: 57984\n",
      "Sample length: 77568\n",
      "Sample length: 83328\n",
      "Sample length: 51456\n",
      "Sample length: 79872\n",
      "Sample length: 49920\n",
      "Sample length: 63744\n",
      "Sample length: 108288\n",
      "Sample length: 49536\n",
      "Sample length: 61824\n",
      "Sample length: 45696\n",
      "Sample length: 112512\n",
      "Sample length: 52608\n",
      "Sample length: 51840\n",
      "Sample length: 76032\n",
      "Sample length: 81024\n",
      "Sample length: 87936\n",
      "Sample length: 61056\n",
      "Sample length: 47616\n",
      "Sample length: 76416\n",
      "Sample length: 49920\n",
      "Sample length: 60672\n",
      "Sample length: 84096\n",
      "Sample length: 80640\n",
      "Sample length: 54144\n",
      "Sample length: 61056\n",
      "Sample length: 53760\n",
      "Sample length: 67200\n",
      "Sample length: 64896\n",
      "Sample length: 66816\n",
      "Sample length: 51840\n",
      "Sample length: 71808\n",
      "Sample length: 67584\n",
      "Sample length: 58752\n",
      "Sample length: 61056\n",
      "Sample length: 57600\n",
      "Sample length: 61440\n",
      "Sample length: 43776\n",
      "Sample length: 59136\n",
      "Sample length: 65664\n",
      "Sample length: 72960\n",
      "Sample length: 83328\n",
      "Sample length: 95616\n",
      "Sample length: 69504\n",
      "Sample length: 67200\n",
      "Sample length: 41088\n",
      "Sample length: 66432\n",
      "Sample length: 102528\n",
      "Sample length: 79872\n",
      "Sample length: 78720\n",
      "Sample length: 76416\n",
      "Sample length: 91008\n",
      "Sample length: 68736\n",
      "Sample length: 56832\n",
      "Sample length: 48384\n",
      "Sample length: 105984\n",
      "Sample length: 53376\n",
      "Sample length: 50688\n",
      "Sample length: 49536\n",
      "Sample length: 53376\n",
      "Sample length: 51456\n",
      "Sample length: 70656\n",
      "Sample length: 42624\n",
      "Sample length: 53376\n",
      "Sample length: 81792\n",
      "Sample length: 66048\n",
      "Sample length: 54528\n",
      "Sample length: 74112\n",
      "Sample length: 59520\n",
      "Sample length: 102144\n",
      "Sample length: 87552\n",
      "Sample length: 69504\n",
      "Sample length: 51456\n",
      "Sample length: 65664\n",
      "Sample length: 82560\n",
      "Sample length: 36864\n",
      "Sample length: 88320\n",
      "Sample length: 59520\n",
      "Sample length: 89472\n",
      "Sample length: 85632\n",
      "Sample length: 54144\n",
      "Sample length: 56448\n",
      "Sample length: 64512\n",
      "Sample length: 70656\n",
      "Sample length: 88704\n",
      "Sample length: 64128\n",
      "Sample length: 111360\n",
      "Sample length: 76416\n",
      "Sample length: 56832\n",
      "Sample length: 70656\n",
      "Sample length: 45312\n",
      "Sample length: 47232\n",
      "Sample length: 44544\n",
      "Sample length: 68736\n",
      "Sample length: 91392\n",
      "Sample length: 60288\n",
      "Sample length: 85632\n",
      "Sample length: 61824\n",
      "Sample length: 59520\n",
      "Sample length: 51072\n",
      "Sample length: 39168\n",
      "Sample length: 68352\n",
      "Sample length: 70656\n",
      "Sample length: 66048\n",
      "Sample length: 49536\n",
      "Sample length: 59136\n",
      "Sample length: 82944\n",
      "Sample length: 72576\n",
      "Sample length: 68736\n",
      "Sample length: 58752\n",
      "Sample length: 88320\n",
      "Sample length: 79488\n",
      "Sample length: 64512\n",
      "Sample length: 92544\n",
      "Sample length: 57984\n",
      "Sample length: 32640\n",
      "Sample length: 68352\n",
      "Sample length: 54912\n",
      "Sample length: 59904\n",
      "Sample length: 58368\n",
      "Sample length: 51456\n",
      "Sample length: 43776\n",
      "Sample length: 60672\n",
      "Sample length: 110592\n",
      "Sample length: 61056\n",
      "Sample length: 39552\n",
      "Sample length: 71040\n",
      "Sample length: 39552\n",
      "Sample length: 39168\n",
      "Sample length: 68352\n",
      "Sample length: 49536\n",
      "Sample length: 44544\n",
      "Sample length: 43008\n",
      "Sample length: 44544\n",
      "Sample length: 60672\n",
      "Sample length: 57600\n",
      "Sample length: 100224\n",
      "Sample length: 80640\n",
      "Sample length: 69888\n",
      "Sample length: 71808\n",
      "Sample length: 78336\n",
      "Sample length: 66048\n",
      "Sample length: 79488\n",
      "Sample length: 43392\n",
      "Sample length: 63360\n",
      "Sample length: 99072\n",
      "Sample length: 59904\n",
      "Sample length: 89472\n",
      "Sample length: 59904\n",
      "Sample length: 67968\n",
      "Sample length: 54912\n",
      "Sample length: 66048\n",
      "Sample length: 52608\n",
      "Sample length: 70656\n",
      "Sample length: 92544\n",
      "Sample length: 69888\n",
      "Sample length: 49920\n",
      "Sample length: 60672\n",
      "Sample length: 52608\n",
      "Sample length: 44160\n",
      "Sample length: 74496\n",
      "Sample length: 70656\n",
      "Sample length: 52608\n",
      "Sample length: 38400\n",
      "Sample length: 43392\n",
      "Sample length: 78720\n",
      "Sample length: 54528\n",
      "Sample length: 83328\n",
      "Sample length: 55680\n",
      "Sample length: 88320\n",
      "Sample length: 57216\n",
      "Sample length: 62976\n",
      "Sample length: 71424\n",
      "Sample length: 49536\n",
      "Sample length: 87168\n",
      "Sample length: 62592\n",
      "Sample length: 72192\n",
      "Sample length: 48384\n",
      "Sample length: 54144\n",
      "Sample length: 49152\n",
      "Sample length: 64512\n",
      "Sample length: 55680\n",
      "Sample length: 97152\n",
      "Sample length: 90624\n",
      "Sample length: 97536\n",
      "Sample length: 39168\n",
      "Sample length: 49536\n",
      "Sample length: 54912\n",
      "Sample length: 56448\n",
      "Sample length: 34176\n",
      "Sample length: 61056\n",
      "Sample length: 67584\n",
      "Sample length: 77568\n",
      "Sample length: 64512\n",
      "Sample length: 91008\n",
      "Sample length: 41088\n",
      "Sample length: 38784\n",
      "Sample length: 69504\n",
      "Sample length: 56064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:170: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded label: li razumete kaj to pomeni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  77%|  | 1000/1307 [06:41<02:03,  2.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample length: 61056\n",
      "Sample length: 43008\n",
      "Sample length: 118656\n",
      "Sample length: 60672\n",
      "Sample length: 61056\n",
      "Sample length: 52992\n",
      "Sample length: 34560\n",
      "Sample length: 75264\n",
      "Sample length: 86784\n",
      "Sample length: 38400\n",
      "Sample length: 36480\n",
      "Sample length: 57600\n",
      "Sample length: 99072\n",
      "Sample length: 53760\n",
      "Sample length: 43008\n",
      "Sample length: 57600\n",
      "Sample length: 66432\n",
      "Sample length: 56064\n",
      "Sample length: 86784\n",
      "Sample length: 52992\n",
      "Sample length: 58752\n",
      "Sample length: 67200\n",
      "Sample length: 52992\n",
      "Sample length: 38784\n",
      "Sample length: 67584\n",
      "Sample length: 59520\n",
      "Sample length: 79488\n",
      "Sample length: 60288\n",
      "Sample length: 57984\n",
      "Sample length: 75264\n",
      "Sample length: 70272\n",
      "Sample length: 53760\n",
      "Sample length: 97152\n",
      "Sample length: 82176\n",
      "Sample length: 84096\n",
      "Sample length: 40704\n",
      "Sample length: 69120\n",
      "Sample length: 83328\n",
      "Sample length: 41856\n",
      "Sample length: 42240\n",
      "Sample length: 74112\n",
      "Sample length: 51072\n",
      "Sample length: 48768\n",
      "Sample length: 52608\n",
      "Sample length: 59904\n",
      "Sample length: 56832\n",
      "Sample length: 48768\n",
      "Sample length: 72576\n",
      "Sample length: 73344\n",
      "Sample length: 64896\n",
      "Sample length: 53760\n",
      "Sample length: 72576\n",
      "Sample length: 59904\n",
      "Sample length: 38400\n",
      "Sample length: 75648\n",
      "Sample length: 78336\n",
      "Sample length: 58368\n",
      "Sample length: 55680\n",
      "Sample length: 83712\n",
      "Sample length: 63744\n",
      "Sample length: 64896\n",
      "Sample length: 55296\n",
      "Sample length: 54144\n",
      "Sample length: 77184\n",
      "Sample length: 72576\n",
      "Sample length: 56448\n",
      "Sample length: 61824\n",
      "Sample length: 75264\n",
      "Sample length: 72576\n",
      "Sample length: 57216\n",
      "Sample length: 65280\n",
      "Sample length: 60672\n",
      "Sample length: 79488\n",
      "Sample length: 89088\n",
      "Sample length: 62208\n",
      "Sample length: 87168\n",
      "Sample length: 75648\n",
      "Sample length: 54528\n",
      "Sample length: 62976\n",
      "Sample length: 64896\n",
      "Sample length: 76416\n",
      "Sample length: 114816\n",
      "Sample length: 86400\n",
      "Sample length: 52608\n",
      "Sample length: 91008\n",
      "Sample length: 63744\n",
      "Sample length: 65664\n",
      "Sample length: 85248\n",
      "Sample length: 61440\n",
      "Sample length: 79872\n",
      "Sample length: 53376\n",
      "Sample length: 74112\n",
      "Sample length: 88320\n",
      "Sample length: 72576\n",
      "Sample length: 63744\n",
      "Sample length: 46080\n",
      "Sample length: 41088\n",
      "Sample length: 107136\n",
      "Sample length: 39168\n",
      "Sample length: 49920\n",
      "Sample length: 89856\n",
      "Sample length: 34176\n",
      "Sample length: 103680\n",
      "Sample length: 61056\n",
      "Sample length: 83328\n",
      "Sample length: 46080\n",
      "Sample length: 64128\n",
      "Sample length: 67200\n",
      "Sample length: 66816\n",
      "Sample length: 54144\n",
      "Sample length: 75648\n",
      "Sample length: 70272\n",
      "Sample length: 77184\n",
      "Sample length: 82944\n",
      "Sample length: 66816\n",
      "Sample length: 77952\n",
      "Sample length: 72960\n",
      "Sample length: 44544\n",
      "Sample length: 53760\n",
      "Sample length: 71040\n",
      "Sample length: 59520\n",
      "Sample length: 46848\n",
      "Sample length: 85632\n",
      "Sample length: 101376\n",
      "Sample length: 66048\n",
      "Sample length: 107520\n",
      "Sample length: 77568\n",
      "Sample length: 109824\n",
      "Sample length: 88704\n",
      "Sample length: 90624\n",
      "Sample length: 77568\n",
      "Sample length: 48384\n",
      "Sample length: 57216\n",
      "Sample length: 77184\n",
      "Sample length: 93696\n",
      "Sample length: 41856\n",
      "Sample length: 61440\n",
      "Sample length: 47232\n",
      "Sample length: 77952\n",
      "Sample length: 68736\n",
      "Sample length: 79872\n",
      "Sample length: 66432\n",
      "Sample length: 56832\n",
      "Sample length: 95616\n",
      "Sample length: 83328\n",
      "Sample length: 66816\n",
      "Sample length: 87168\n",
      "Sample length: 59520\n",
      "Sample length: 66816\n",
      "Sample length: 78336\n",
      "Sample length: 106752\n",
      "Sample length: 94080\n",
      "Sample length: 79872\n",
      "Sample length: 72192\n",
      "Sample length: 79104\n",
      "Sample length: 86016\n",
      "Sample length: 82176\n",
      "Sample length: 84480\n",
      "Sample length: 69888\n",
      "Sample length: 62976\n",
      "Sample length: 40320\n",
      "Sample length: 85632\n",
      "Sample length: 68736\n",
      "Sample length: 90240\n",
      "Sample length: 44928\n",
      "Sample length: 35328\n",
      "Sample length: 53376\n",
      "Sample length: 69504\n",
      "Sample length: 56064\n",
      "Sample length: 81408\n",
      "Sample length: 49152\n",
      "Sample length: 48768\n",
      "Sample length: 54144\n",
      "Sample length: 62208\n",
      "Sample length: 67968\n",
      "Sample length: 96384\n",
      "Sample length: 41088\n",
      "Sample length: 49536\n",
      "Sample length: 49536\n",
      "Sample length: 86016\n",
      "Sample length: 29568\n",
      "Sample length: 76800\n",
      "Sample length: 40704\n",
      "Sample length: 60672\n",
      "Sample length: 56448\n",
      "Sample length: 48384\n",
      "Sample length: 82176\n",
      "Sample length: 57216\n",
      "Sample length: 75648\n",
      "Sample length: 42240\n",
      "Sample length: 38400\n",
      "Sample length: 79872\n",
      "Sample length: 31104\n",
      "Sample length: 83328\n",
      "Sample length: 86784\n",
      "Sample length: 88704\n",
      "Sample length: 71040\n",
      "Sample length: 135552\n",
      "Sample length: 31872\n",
      "Sample length: 112896\n",
      "Sample length: 62976\n",
      "Sample length: 45696\n",
      "Sample length: 86016\n",
      "Sample length: 43776\n",
      "Sample length: 43776\n",
      "Sample length: 39936\n",
      "Sample length: 53376\n",
      "Sample length: 50688\n",
      "Sample length: 71808\n",
      "Sample length: 48000\n",
      "Sample length: 59136\n",
      "Sample length: 51456\n",
      "Sample length: 75648\n",
      "Sample length: 34176\n",
      "Sample length: 49920\n",
      "Sample length: 46848\n",
      "Sample length: 53376\n",
      "Sample length: 71424\n",
      "Sample length: 109824\n",
      "Sample length: 62976\n",
      "Sample length: 54528\n",
      "Sample length: 61440\n",
      "Sample length: 71424\n",
      "Sample length: 110592\n",
      "Sample length: 66432\n",
      "Sample length: 61824\n",
      "Sample length: 58368\n",
      "Sample length: 85248\n",
      "Sample length: 104064\n",
      "Sample length: 49920\n",
      "Sample length: 54528\n",
      "Sample length: 56448\n",
      "Sample length: 49152\n",
      "Sample length: 60672\n",
      "Sample length: 67968\n",
      "Sample length: 49920\n",
      "Sample length: 67584\n",
      "Sample length: 88320\n",
      "Sample length: 78720\n",
      "Sample length: 67968\n",
      "Sample length: 71040\n",
      "Sample length: 86784\n",
      "Sample length: 51840\n",
      "Sample length: 81024\n",
      "Sample length: 68736\n",
      "Sample length: 44928\n",
      "Sample length: 57216\n",
      "Sample length: 73344\n",
      "Sample length: 46080\n",
      "Sample length: 49920\n",
      "Sample length: 50304\n",
      "Sample length: 58752\n",
      "Sample length: 37248\n",
      "Sample length: 66432\n",
      "Sample length: 66432\n",
      "Sample length: 39936\n",
      "Sample length: 77568\n",
      "Sample length: 104832\n",
      "Sample length: 49920\n",
      "Sample length: 68352\n",
      "Sample length: 96768\n",
      "Sample length: 65664\n",
      "Sample length: 45696\n",
      "Sample length: 58752\n",
      "Sample length: 53376\n",
      "Sample length: 61440\n",
      "Sample length: 81024\n",
      "Sample length: 39936\n",
      "Sample length: 61440\n",
      "Sample length: 67584\n",
      "Sample length: 44544\n",
      "Sample length: 65664\n",
      "Sample length: 77184\n",
      "Sample length: 73344\n",
      "Sample length: 54528\n",
      "Sample length: 77184\n",
      "Sample length: 65280\n",
      "Sample length: 79104\n",
      "Sample length: 62976\n",
      "Sample length: 56832\n",
      "Sample length: 75264\n",
      "Sample length: 67968\n",
      "Sample length: 75264\n",
      "Sample length: 95616\n",
      "Sample length: 59904\n",
      "Sample length: 60288\n",
      "Sample length: 77568\n",
      "Sample length: 62592\n",
      "Sample length: 40704\n",
      "Sample length: 90624\n",
      "Sample length: 84480\n",
      "Sample length: 73344\n",
      "Sample length: 66816\n",
      "Sample length: 85248\n",
      "Sample length: 61056\n",
      "Sample length: 105600\n",
      "Sample length: 59904\n",
      "Sample length: 81024\n",
      "Sample length: 72960\n",
      "Sample length: 98688\n",
      "Sample length: 44928\n",
      "Sample length: 64896\n",
      "Sample length: 69120\n",
      "Sample length: 49152\n",
      "Sample length: 84864\n",
      "Sample length: 63744\n",
      "Sample length: 75264\n",
      "Decoded label: arko je udaril s pestjo po mizi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1307/1307 [08:41<00:00,  2.51 examples/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:52:36.557540Z",
     "start_time": "2025-07-28T18:52:36.502600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class DataCollator:\n",
    "    processor: Wav2Vec2Processor\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input = self.processor.pad([{\"input_values\": f[\"input_values\"]} for f in features], return_tensors=\"pt\")\n",
    "        with self.processor.as_target_processor():\n",
    "            labels = self.processor.pad([{\"input_ids\": f[\"labels\"]} for f in features], return_tensors=\"pt\")\n",
    "        input[\"labels\"] = labels[\"input_ids\"].masked_fill(labels[\"attention_mask\"].ne(1), -100)\n",
    "        return input"
   ],
   "id": "11c4364423c3a229",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T18:52:36.739065Z",
     "start_time": "2025-07-28T18:52:36.701361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jiwer import wer\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    print(\"Raw:\", pred.predictions.shape)\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    for ref, hyp in zip(label_str[:5], pred_str[:5]):\n",
    "        print(f\"REF : {ref}\")\n",
    "        print(f\"PRED: {hyp}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "    error = wer(label_str, pred_str)\n",
    "    return {\"wer\": error}"
   ],
   "id": "149dec59af78e459",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-28T18:52:36.839147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./slovene-model\",\n",
    "        per_device_train_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        logging_steps=10,\n",
    "        eval_steps=20,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_steps=50,\n",
    "        save_total_limit=1,\n",
    "        report_to=[]\n",
    "    ),\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=processor,\n",
    "    data_collator=DataCollator(processor),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(trainer.evaluate())"
   ],
   "id": "e2a2d18cb9f1fec3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lerab\\AppData\\Local\\Temp\\ipykernel_41748\\2521648828.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:170: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "D:\\PythonProject\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='882' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16/882 08:08 < 8:23:50, 0.03 it/s, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(processor.tokenizer.get_vocab().keys())",
   "id": "2f22d6d213bdbc3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(dataset.column_names)",
   "id": "a8a26d13cbfafbd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b7ce786eac4379d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
